"use strict";Object.defineProperty(exports,"__esModule",{value:true});exports.METADATA_STORAGE={instanceClass:{label:"Instance class",description:'The <a href="http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html" target="_blank">\n      AWS DB instance class\n    </a> used for the metadata storage.'},sizeGb:{label:"Size GB",description:"The max size, in GB of the metadata storage. This can be increased in the future but can never be decreased. \n    Druid requires very little metadata storage."},masterUsername:{label:"Master username",description:"The root username used by Imply to initialize the metadata storage"},masterPassword:{label:"Master password",description:"The root password used by Imply to initialize the metadata storage"},backupRetentionDays:{label:"Backup retention days",description:"The number of days that daily backups of the metadata storage will be retained for"},snapshotIdentifier:{label:"Snapshot identifier",description:"Causes the metadata store to be seeded with data from an RDS snapshot. \n    It can be useful for cloning a cluster from another cluster or re-creating a cluster from a backup after a failure."},highlyAvailable:{label:"Highly available",description:"High availability is recommended for production clusters."}};exports.CUSTOM_DRUID_PROPERTIES={coordinator:{label:"Coordinator",description:'Override properties for the <a href="http://druid.io/docs/latest/configuration/coordinator.html" target="_blank">coordinator node</a>'},common:{label:"Common",description:'This describes the <a href="http://druid.io/docs/latest/configuration/index.html" target="_blank">common configuration</a> shared by all Druid nodes.'},historical:{label:"Historical",description:'Override properties for the <a href="http://druid.io/docs/latest/configuration/historical.html" target="_blank">historical node</a>'},middleManager:{label:"Middle manager",description:'Override properties for the <a href="http://druid.io/docs/latest/configuration/indexing-service.html" target="_blank">middle manager node</a>'},broker:{label:"Broker",description:'Override properties for the <a href="http://druid.io/docs/latest/configuration/broker.html" target="_blank">broker node</a>'},overlord:{label:"Overlord",description:'Override properties for the <a href="http://druid.io/docs/latest/configuration/indexing-service.html" target="_blank">overlord node</a>'}};exports.DRUID_CLUSTER={name:{label:"Name"},implyVersion:{label:"Imply version"},instanceRole:{label:"Instance role",description:'The <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html" target="_blank">\n      AWS instance role\n    </a> assigned to the created instances'},dataInstanceType:{label:"Instance type",description:'The <a href="https://aws.amazon.com/ec2/instance-types" target="_blank">\n      AWS instance type\n    </a> assigned to the data servers'},dataInstanceCount:{label:"Number of servers",description:"Number of servers"},dataCapacity:{label:"Segment capacity",description:"This is the storage capacity for the data servers"},dataWorkerCapacity:{label:"Worker capacity",description:"Maximum number of tasks the middle manager can accept"},queryInstanceType:{label:"Instance type",description:'The <a href="https://aws.amazon.com/ec2/instance-types" target="_blank">\n      AWS instance type\n    </a> assigned to the query servers'},queryInstanceCount:{label:"Number of servers",description:"Number of servers"},masterInstanceType:{label:"Instance type",description:'The <a href="https://aws.amazon.com/ec2/instance-types" target="_blank">\n      AWS instance type\n    </a> assigned to the master servers'},masterInstanceCount:{label:"Number of servers"},keyPairName:{label:"AWS keypair name",description:'The <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html" target="_blank">\n      AWS key pair\n    </a> to set on the machines. Setting a key pair allows you to SSH into the machines.\n    Provide the key pair name as listed in the AWS console, not the filename of the private key.'},s3Location:{label:"S3 bucket override",description:"An optional S3 bucket to be used for druid data storage instead of the default one provided by Imply."},dataTotalCores:{label:"Data total cores"},dataTotalMemory:{label:"Data total memory"},queryTotalCores:{label:"Query total cores"},queryTotalMemory:{label:"Query total memory"},customDruidProperties:exports.CUSTOM_DRUID_PROPERTIES,extensionLoadList:{label:"Druid extensions"},metadataStorage:exports.METADATA_STORAGE};exports.DATA_SOURCE={name:{label:"Name"},size:{label:"Total size"},segmentCount:{label:"Segments"},averageSegmentSize:{label:"Average segment size"},intervalCount:{label:"Intervals"},columnCount:{label:"Columns"},runningTasks:{label:"Running tasks"},latestTask:{label:"Latest task"},loaded:{label:"Loaded"},lastEvent:{label:"Last event"}};exports.DATA_LOADER_SPEC={cluster:{label:"Cluster",description:""},dataSource:{label:"Datasets",description:""},s3Prefix:{label:"S3 prefix",description:""},uris:{label:"uri(s)",description:""},format:{label:"Format",description:""},isNested:{label:"Nested",description:""},isHeadered:{label:"Has header"},rollup:{label:"Rollup options",description:'Druid summarizes this raw data at ingestion time using a process we refer to as "roll-up". \n    Roll-up is a first-level aggregation operation over a selected set of dimensions. <a href="http://druid.io/docs/latest/design/index.html#roll-up">Read more here.</a>'},segmentGranularity:{label:"Segment granularity"},maxRowsInMemory:{label:"Max rows in memory"}};exports.AGGREGATION={type:{label:"Aggregation type",description:'Aggregations can be provided at ingestion time as part of the ingestion spec as a way of summarizing data before it enters Druid.\n     <a href="http://druid.io/docs/latest/querying/aggregations.html">Read more here.</a>'},fnAggregate:{label:"fnAggregate",description:"Updates partial aggregate (current) based on the current row values.\n    <code>function(current, column1, column2, ...){\n     return $(updated partial aggregate)\n    }</code>"},fnCombine:{label:"fnCombine",description:"<code>function(partialA, partialB) { return $(combined partial results); }</code>"},fnReset:{label:"fnReset",description:"<code>function(){ return $(initialValue); }</code>"},filter:{label:"filter",description:'Apply a <a href="http://druid.io/docs/latest/querying/filters.html" target="_blank">dimension filter</a> to your aggregator.'},aggregator:{label:"aggregator"},byRow:{label:"By row",description:"When setting byRow to true it computes the cardinality by row, i.e. the cardinality of distinct dimension combinations."},resolution:{label:"resolution",description:"Number of centroids (data points) to store. The higher the resolution, the more accurate results are, but the slower the computation will be."},numBuckets:{label:"Number of buckets",description:"Number of output buckets for the resulting histogram. Bucket intervals are dynamic, \n    based on the range of the underlying data. Use a post-aggregator to have finer control over the bucketing scheme."},lowerLimit:{label:"Lower limit",description:"Restrict the approximation to the given range. The values outside this range will be aggregated into two centroids. Counts of values outside this range are still maintained."},upperLimit:{label:"Upper limit",description:"Restrict the approximation to the given range. The values outside this range will be aggregated into two centroids. Counts of values outside this range are still maintained."},isInputThetaSketch:{label:"Input is theta sketch",description:"This should only be used if your input data contains theta sketch objects. This would be the case if you use datasketches library outside of Druid, \n    say with Pig/Hive, to produce the data that you are ingesting into Druid"},size:{label:"size",description:'Must be a power of 2. Internally, size refers to the maximum number of entries sketch object will retain. \n    Higher size means higher accuracy but more space to store sketches.\n    Note that after you index with a particular size, druid will persist sketch in segments and you will use size greater or equal to that at query time. \n    See  <a href="http://datasketches.github.io/docs/ThetaSize.html" target="_blank">theta-size</a> for details. In general, We recommend just sticking to default size.'}};exports.COLUMN_DEFINITION={name:{label:"Ingested name",description:"Name column will have in druid"},namesInData:{label:"Column names",description:"Name of columns in data"},nameInData:{label:"Column name",description:"Name of column in data"},type:{label:"Type",description:""},timestampFormat:{label:"Timestamp format",description:""},rollupType:{label:"Rollup type"},aggregation:exports.AGGREGATION,granularity:{label:"Query granularity",description:"Value at which to truncate your data. The minimum granularity to be able to query results at and the granularity of the data inside the segment."}};exports.CLUSTER_API={masterServer:{label:"Overlord server",description:'The <a href="http://druid.io/docs/latest/design/indexing-service.html" target="_blank">Overlord server</a> \n    is responsible for accepting tasks, coordinating task distribution, creating locks around tasks, and returning statuses to callers.'},queryLoadBalancer:{label:"Query load balancer",description:'The load balancer in front of the <a href="https://imply.io/docs/latest/index#query-server" target="_blank">Query servers</a>. '},coordinatorServer:{label:"Coordinator server",description:'The <a href="http://druid.io/docs/latest/configuration/coordinator.html" target="_blank">Coordinator server</a>\n    is primarily responsible for segment management and distribution.'},jdbcConnectionString:{label:"JDBC connection string",description:"You can make Druid SQL queries using the Avatica JDBC driver. \n    Once you've downloaded the Avatica client jar, add it to your classpath and use this connect string."}};